# -*- coding: utf-8 -*-
"""
Created on Tue Feb 18 22:07:02 2020

@author: samwh
"""

import random
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

from keras.models     import Sequential
from keras.layers     import Dense
from keras.models     import load_model


'''
Import gym environments - uncomment the environment to be used
'''
import gym
gym.logger.set_level(40)
#env = gym.make('BipedalWalker-v3')
env = gym.make('CartPole-v1')
env.reset()


#from Pymunk import Swing
#env = Swing()


# lists containing model activations and optimizers to allow for randomisation
hidden_layer_activations = ['tanh', 'relu', 'sigmoid', 'linear', 'softmax']
model_optimizers = ['adam', 'rmsprop']


'''
Function taken from online example for running the OpenAI cartpole gym environment: 
https://blog.tanka.la/2018/10/19/build-your-first-ai-game-bot-using-openai-gym-keras-tensorflow-in-python/
'''
# function to trial neural model over specified number of games, called by run_sim()
def play_cart(model, goal_steps=500, render=False, games=100, _print=True):
    
    scores = []
    choices = []
    
    for each_game in range(games):
        score = 0
        prev_obs = []
        for step_index in range(goal_steps):
            if render: env.render()
            if len(prev_obs)==0:
                action = random.randrange(0,2)
            else:
                action = np.argmax(model.predict(prev_obs))
                
            choices.append(action)
            new_observation, reward, done, info = env.step(action)
            prev_obs = new_observation
            score+=reward
            if done:
                break
        if _print: print('Score: ' + str(score))
        
        env.reset()
        scores.append(score)
        
    return sum(scores)/len(scores)


'''
Simulation function for PyMunk Swing
'''
def pymunk_swing(model, goal_steps=100, render=False, games=1, _print=True):
    
    scores = []
    choices = []
    
    for each_game in range(games):
        score = 0
        prev_obs = []
        done = False
        while not done:
            if render: env.render(model)
            if len(prev_obs)==0:
                action = random.randrange(0,4)
            else:
                action = np.argmax(model.predict(prev_obs))   
            choices.append(action)
            new_observation, reward, done, info = env.step(action)
            prev_obs = new_observation
            score+=reward
        if _print: print('Score: ' + str(score))
        
        env.reset()
        scores.append(score)
        
    return sum(scores)/len(scores)


###############################################################################
 

'''
Section 3

Classes and functions used for NEAT:
    - All NEAT data (both parameters and population data) stored in NEAT object
    - If no initial population is provided a random set of genomes is generated automatically
    - NEAT.run() iterates through the NEAT algorithm up to 'max_generations' gens
    - The top genomes in each generation are carried through to the next (given by 'breed_ratio')
    - The rest of the population is generated by calling the crossover() function iteratively
    - Random parents are selected from all parent genomes to breed (no speciation yet)
    - Each child is the mutated by calling the mutate() method from Section 2
    - NEAT.run() returns the best model (NeuralNet object) and a list of all winning genomes
'''
           
            
# object class for storing instance of a global innovation number
class GIN():
    
    def __init__(self, val=0):
        
        self.val = val
        
    
    # increments the innovation value and returns the new value, improving code efficiency
    def i(self):
        
        self.val += 1
              
        return self.val
    
    
    # decrements innovation value
    def decrement(self):
        
        self.val -= 1
        
        return self.val
    
    
    # resets innovation value to 0
    def reset(self):
        
        self.val = 0
        
        
# class to store genetic information common to the entire NEAT population
class NEAT():
    
    def __init__(self,  
                input_size, 
                output_size,
                population_size = 50,
                max_generations = 20,
                breed_ratio = 0.25,                 # percentage of genomes allowed to continue to next gen
                activations = ['sigmoid'],
                
                avg_of = 1,                         # no. of times to run sim for each fitness calculation
                best_model_runs = 1,                # no. of times to show sim with best model each generation
                
                population = None,
                gin = None,
                
                # crossover parameters
                deactivate_prob = 0.5,              # prob to deactivate gene if deactivated in either parent
                
                # mutation parameters
                add_node_prob = 0.1,
                add_connection_prob = 0.1,
                alt_weight_prob = 0.1,
                alt_weight_gauss = True,
                alt_weight_std = None,
                alt_bias_prob = 0.1
                ):
               
        self.input_size, self.output_size = input_size, output_size
        self.population_size = population_size
        self.max_generations = max_generations
        self.breed_ratio = breed_ratio
        self.activations = activations
        
        self.avg_of = avg_of
        self.best_model_runs = best_model_runs
        
        self.population = population
        self.gin = gin
        
        self.node_genes = []
        self.connection_vectors = []
        self.winning_genomes = []
        self.best_model = None

        self.deactivate_prob = deactivate_prob
        
        self.add_node_prob = add_node_prob
        self.add_connection_prob = add_connection_prob
        self.alt_weight_prob = alt_weight_prob
        self.alt_weight_gauss = alt_weight_gauss
        self.alt_weight_std = alt_weight_std
        self.alt_bias_prob = alt_bias_prob
        
        if not gin: self.gin = GIN()
        if not population: self.population = gen_init_population(neat_data = self)
        else: self.gin.val = max([[c.innovation for c in g.connection_genes] for g in population])
        
        
    # main NEAT method
    def run(self, generations=None, _print=True, render=True):
        
        if not generations: generations = self.max_generations
        
        for gen in range(generations):
            
            fitness_dist, parents, new_population = [], [], []
            best_genome = None

            # iterate through new population
            for genome in tqdm(self.population):

                model = genome.compile_network()
                
                # find and record fitness value for each model
                genome.fitness = run_sim(model, render=False, games=self.avg_of, _print=False)
                fitness_dist.append(genome.fitness)
            
            # find the 'threshold' fitness based on the percentage of models allowed to survive
            fitness_dist.sort(reverse=True)
            fitness_threshold = fitness_dist[int(self.population_size*self.breed_ratio)]
            
            # find the best fitness of the generation
            best_fitness = fitness_dist[0]
            
            # use the above to find the best models in the generation            
            for genome in self.population:
                
                if genome.fitness >= fitness_threshold: 
                    
                    parents.append(genome)
                    if genome.fitness == best_fitness and not best_genome: best_genome = genome
            
            self.winning_genomes.append(best_genome)
            self.best_model = best_genome.model
            
            if _print:
                
                print('\nBest genome for gen {} (score = {}):'.format(gen, best_fitness))
                if gen > 0 and best_genome == self.winning_genomes[-2]: print('(same as last gen)')
                print('Connection weights:')
                best_genome.get_connection_info()
            
            if self.best_model_runs > 0:
                run_sim(model=best_genome.model, render=render, games=self.best_model_runs, _print=False)
            
            # generate new population from best genomes in generation           
            for i in range(self.population_size - len(parents)):
                
                # choose random parent genomes
                parent1 = random.choice(parents)
                parent2 = random.choice([p for p in parents if p != parent1])
                
                # generate child via crossover method and mutate it
                child = crossover(parent1, parent2)
                child.mutate(params=self)
                
                # add child to new population
                new_population.append(child)
            
            self.population = parents + new_population
            
        # returns best_model (NeuralNet object) and list of winning genomes (Genome objects)
        return self.best_model, self.winning_genomes


def gen_init_population(neat_data = None, 
                        rand = True,
                        
                        population_size = None,
                        input_size = None, 
                        output_size = None,
                        gin = None, 
                        activations = ['sigmoid'], 
                        optimizers = ['adam'], 
                        ):
    
    # subfunction returns zero unless rand=True, in which case returns a random number from -1 to 1
    def new_val():
        
        if rand: return 2*random.random() - 1
        else: return 0
        
    # subfunction to handle mutations with no global innovation number
    def gin_i():
        
        if gin: return gin.i()
        else: return 0
    
    if neat_data:
        
        population_size = neat_data.population_size
        input_size = neat_data.input_size
        output_size = neat_data.output_size
        gin = neat_data.gin
        activations = neat_data.activations
    
    # generate lists of input and output nodes and add them to the neat_data
    input_nodes, output_nodes = [], []
    
    for i in range(input_size + output_size):
        
        if i < input_size: input_nodes.append(NodeGene(num=i+1, layer=0))
        else: output_nodes.append(NodeGene(num=i+1, layer=1))
        
    if neat_data: neat_data.node_genes += input_nodes + output_nodes
    
    # generate initial population of genomes with densely connected outer layers
    init_population = []    
    
    for i in range(population_size):
        
        # generate connections between layers after resetting the innovation number to zero
        new_connections = []       
        if gin: gin.reset()
        
        for input_node in input_nodes:
            new_connections += [input_node.add_connection(output_node, 
                                                          new_val(), 
                                                          innovation = gin_i()) 
                                for output_node in output_nodes]
         
        # generate the genome object with node/connection gene information, and add it to the population
        init_genome = Genome(connection_genes = new_connections,           
                                 node_genes = input_nodes + output_nodes,                 
                                 input_size = input_size, 
                                 output_size = output_size,
                                 activation = random.choice(activations),              
                                 optimizer = random.choice(optimizers)
                                 )
        
        init_population.append(init_genome)
    
    return init_population


# function to mark disjoint and excess genes between two genomes
def mark_disjoint_excess(genome1, genome2):

    # generate copies of each genome gene list
    genome1_genes = [c for c in genome1.connection_genes]    
    genome2_genes = [c for c in genome2.connection_genes]
    
    # sort each gene list by innovation number
    genome1_genes.sort(key=lambda x: x.innovation)
    genome2_genes.sort(key=lambda x: x.innovation)
    
    # generate lists of innovation numbers present in each genome
    genome1_innovations = [c.innovation for c in genome1_genes]
    genome2_innovations = [c.innovation for c in genome2_genes]
    
    for i in range(max(genome1_innovations + genome2_innovations) + 1):
        
        # insert null into gene lists in place of all missing innovations        
        if i not in genome1_innovations: genome1_genes.insert(i, None)
        if i not in genome2_innovations: genome2_genes.insert(i, None)
        
        # mark disjoint and excess genes
        if i in genome1_innovations:
            
            if i in genome2_innovations:
                
                for gene in [genome1_genes[i], genome2_genes[i]]: gene.disjoint, gene.excess = False, False

            else: 
                
                genome1_genes[i].disjoint = (i < max(genome2_innovations)) 
                genome1_genes[i].excess = (i > max(genome2_innovations))
            
        elif i in genome2_innovations: 
            
            genome2_genes[i].disjoint = (i < max(genome1_innovations)) 
            genome2_genes[i].excess = (i > max(genome1_innovations)) 
            
    return genome1_genes, genome2_genes, genome1_innovations, genome2_innovations


# generate a child genome through crossover of two parent genomes
def crossover(genome1, genome2, params=None, deactivate_prob=0.5):
    
    # inherit crossover parameters from NEAT object
    if params: deactivate_prob = params.deactivate_prob
    
    # set parent1 to be the genome with the best fitness
    if genome2.fitness > genome1.fitness: parent1, parent2 = genome2, genome1
    else: parent1, parent2 = genome1, genome2
    
    # mark disjoint and excess genes
    parent1_genes, parent2_genes, parent1_innovations, parent2_innovations = mark_disjoint_excess(parent1, parent2)
    
    # add disjoint and excess genes from most fit parent to child genes
    child_genes = [g.copy() for g in parent1_genes if g and g.disjoint or g and g.excess]
    
    # iterate through innovations common to both parents
    for i in (i for i in parent1_innovations if i in parent2_innovations):
        
        # randomly choose a parent from which to inherit the gene
        child_genes.append(random.choice([parent1_genes[i], parent2_genes[i]]).copy())
        
        # probabilistically deactivate gene if deactivated in either parent
        if random.random() < deactivate_prob and not parent1_genes[i].activated or not parent2_genes[i].activated:
            
            child_genes[-1].activated = False
    
    # generate child genome from new genes
    child = parent1.copy()   
    child.connection_genes = child_genes
    child.biased_nodes = [n for n in parent1.biased_nodes]
    child.fitness = None
    
    return child


# function to run simulation with optional rendering and return a fitness value  
# currently this simply calls the 'play_cart' function which runs the cartpole gym env
def run_sim(model, goal_steps=500, render=False, games=1, _print=False):
    
    fitness = play_cart(model, goal_steps, render, games, _print)
    
    return fitness
   

###############################################################################
    

# initialise NEAT object (increase best_model_runs to show each winning genome perform)
neat = NEAT(input_size=4, output_size=2, population_size=10, breed_ratio = 0.25, 
            add_node_prob=0.1, add_connection_prob=0.1, alt_weight_prob=0.1, alt_bias_prob=0.1,
            avg_of=10, best_model_runs=1
            )

# run NEAT
best_model, winning_genomes = neat.run(generations=20)


#model = NeuralNet(input_size=4, output_size=2, file='NEATv1_model.h5')
#run_sim(model, render=True, goal_steps=20000)

# save best model to .h5
#neat.best_model.save('NEATv1_model')

'''
pop = neat.population
# pop = gen_init_population(input_size=4, output_size=2, population_size=10, neat_data=neat)
print('neat nodes:', [n.num for n in neat.node_genes])
pop[0].get_connection_info()
model = pop[0].compile_network()
model.get_weights(_print=True)

pop[0].mutate(params=neat)
print('neat nodes:', [n.num for n in neat.node_genes])
pop[0].get_connection_info()
model = pop[0].compile_network()
model.get_weights(_print=True)
'''
'''
#pop[9].get_node_info()
pop[0].get_connection_info()
pop[1].get_connection_info()
pop[0].fitness, pop[1].fitness = 1,2
#pop[9].compile_network()
child = crossover(pop[0], pop[1], params=neat)
pop[0].get_connection_info()
pop[1].get_connection_info()
child.get_connection_info()
'''

'''
d = NEAT(input_size=4, output_size=2)

pop = gen_init_population(d,
                          population_size=10
                          )

for p in pop: p.get_node_info()
'''
'''
input1 = NodeGene(num=1, layer=0)
input2 = NodeGene(num=2, layer=0)
input3 = NodeGene(num=3, layer=0)
input4 = NodeGene(num=4, layer=0)
hidden5 = NodeGene(num=5, layer=0.5)
output6 = NodeGene(num=6, layer=1)
output7 = NodeGene(num=7, layer=1)

con1 = input1.add_connection(hidden5, weight=0.1, innovation=0)
con2 = input2.add_connection(hidden5, weight=0.2, innovation=4)
con3 = input3.add_connection(hidden5, weight=0.3, innovation=3)
con4 = input4.add_connection(output7, weight=0.4, innovation=1)
con5 = hidden5.add_connection(output7, weight=0.5, innovation=7)

con6 = hidden5.add_connection(output6, weight=0.6, innovation=9)
con7 = input4.add_connection(output6, weight=0.7, innovation=5)

activation=hidden_layer_activations[random.randint(0,len(hidden_layer_activations)-1)]
optimizer=model_optimizers[random.randint(0,len(model_optimizers)-1)]

genome = Genome(connection_genes=[con1, con2, con3, con4, con5],
                node_genes=[input1, input2, input3, input4,
                            hidden5,
                            output6, output7],
                activation=activation,
                optimizer=optimizer
                )

genome2 = genome.copy()
genome2.connection_genes.append(con6)
genome2.connection_genes.append(con7)

genome.fitness = 1
genome2.fitness = 2

NN = genome.compile_network()
NN.get_weights(_print=True) 

child = crossover(genome, genome2)
child.mutate(alt_weight_prob=1,
             add_node_prob=1)
print([p.innovation for p in child.connection_genes])
child.get_node_info()
child.get_connection_info()
'''
